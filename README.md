# ğŸ§  AI-Based Automotive Test Procedure Generator

## ğŸ“˜ Problem Statement

In automotive validation, requirement documents are lengthy, complex, and often reference multiple technical standards or related documents.  
Manually converting these requirements into **detailed, structured test procedures** is time-consuming, error-prone, and inconsistent across engineers.

This tool automates that process using **AI-driven text understanding** â€” generating **structured Excel test cases** directly from a requirements document (PDF, DOCX, XLSX, or TXT).  
It ensures consistency in **naming, step sequence, action/expected result formatting**, and supports contextual understanding via **RAG (Retrieval-Augmented Generation)**.

---

## ğŸ§© Approach

### ğŸ”¹ Step 1: Requirement Document Ingestion
- Input requirement documents (main + related references) are read from the `requirements_docs/` folder.
- Supported formats: `.pdf`, `.docx`, `.xlsx`, `.txt`
- Each document is **text-extracted**, cleaned, and **chunked** into overlapping sections for contextual embeddings.

### ğŸ”¹ Step 2: RAG Index Construction
- Uses **SentenceTransformer** (`all-MiniLM-L6-v2`) to embed each chunk.
- Stores embeddings in a **FAISS** index for efficient semantic retrieval.
- During generation, the tool retrieves the top contextually relevant chunks for the given requirement.

### ğŸ”¹ Step 3: AI Test Case Generation
- Uses **Mistralâ€™s API (e.g., `mistral-large-latest`)** for natural language understanding.
- The prompt guides Mistral to generate:
  - Structured JSON output with keys: `test_name`, `test_description`, `steps`
  - Each step includes `step_name`, `action`, and `expected_result`
- The generation process runs **chunked** to handle long documents robustly.
- If partial JSON or incomplete response is returned, the script:
  - Saves failed chunks to `failed_chunk_X.json`
  - Re-requests Mistral to repair or complete the JSON automatically

### ğŸ”¹ Step 4: Output Formatting
- Parses AI responses safely (via custom `safe_json_parse`)
- Merges results from all chunks
- Converts structured JSON into a final Excel sheet:
  ```
  | Test Name | Test Description | Step Name | Action Description | Expected Results |
  ```
- Ensures:
  - Numbered test names (e.g., `001_...`)
  - Step names reset per test (`Step 1`, `Step 2`, â€¦)
  - No missing expected results

---

## âš™ï¸ Tech Stack & Libraries

| Library | Purpose | Why Itâ€™s Used |
|----------|----------|---------------|
| **PyPDF2** | PDF text extraction | Handles automotive requirement PDFs with embedded text |
| **docx**, **openpyxl** | Reading `.docx` and `.xlsx` files | Many requirements are shared as Word or Excel documents |
| **SentenceTransformers** | Sentence embeddings | Enables semantic chunking and similarity-based RAG |
| **FAISS** | Vector similarity search | Efficient retrieval of most relevant requirement chunks |
| **Requests** | Mistral API calls | Clean, lightweight HTTP requests |
| **json / re** | Parsing AI outputs | Robust JSON repair and cleanup |
| **Pandas** | Writing Excel output | Generates readable structured test procedure Excel |
| **Torch** | Backend for SentenceTransformer | Utilizes GPU acceleration if available |

---

## ğŸ§  Why RAG (Retrieval-Augmented Generation)?

Automotive requirement documents are often:
- Spread across multiple files (e.g., functional, HMI, CAN signal specs)
- Contain cross-references (e.g., â€œas defined in ISO15118â€)
- Updated incrementally

RAG ensures that the model:
- Retrieves **relevant background context** dynamically  
- Generates **accurate and consistent test cases** even if input doc lacks all details

---

## ğŸš€ How to Run

### **1ï¸âƒ£ Environment Setup**
```bash
git clone https://github.com/<your-username>/TestProcedureGenerator.git
cd TestProcedureGenerator
python -m venv venv
venv\Scripts\activate  # (Windows)
# or
source venv/bin/activate  # (Linux/Mac)
pip install -r requirements.txt
```

### **2ï¸âƒ£ Folder Structure**
```
TestProcedureGenerator/
â”‚
â”œâ”€â”€ requirements_docs/
â”‚   â”œâ”€â”€ ISO15118_requirements.pdf
â”‚   â”œâ”€â”€ PlugNCharge_DesignSpec.docx
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ PlugNCharge_requirements_doc.xlsx
â”œâ”€â”€ main_notebook.ipynb
â”œâ”€â”€ main.py
â”œâ”€â”€ output/
â”‚   â””â”€â”€ generated_tests.xlsx
â””â”€â”€ failed_chunk_X.json
```

### **3ï¸âƒ£ Run via Command Line**
```bash
python main.py   --index_dir ./requirements_docs   --query_doc ./PlugNCharge_requirements_doc.xlsx   --mistral_api_key <YOUR_MISTRAL_API_KEY>   --out_excel ./output/generated_tests.xlsx
```

### **4ï¸âƒ£ Run via Notebook**
- Open `main_notebook.ipynb`
- Execute all cells sequentially
- Failed chunks will be automatically retried and logged

---

## ğŸ§¾ Output Example

| Test Name | Test Description | Step Name | Action Description | Expected Results |
|------------|------------------|------------|--------------------|------------------|
| 001_To Check Plug & Charge Activation | To Check Plug & Charge Activation | Step 1 | Set below CAN signalsâ€¦ | Plug & Charge should activate |
| 002_To Verify HMI Display | To Verify HMI Display | Step 1 | Open Plug & Charge HMI page | HMI displays expected fields |

---

## ğŸ§° Troubleshooting

| Issue | Likely Cause | Fix |
|--------|--------------|-----|
| âŒ 400/401 Error | Invalid or expired Mistral API key | Regenerate API key |
| âŒ JSON parsing failed | Model returned incomplete JSON | Check `failed_chunk_X.json` |
| âš ï¸ Long runtime | Large doc or CPU embedding | Use GPU or smaller embedding model |
| ğŸš« Missing output Excel | File path issue | Ensure correct `--out_excel` path |

---

## ğŸ§‘â€ğŸ’» Author & Credits

Developed by **Kanishk Mishra**  
AI Intern at **RNTBCI (Renault Nissan Technology & Business Centre India)**  
Focus: *AI for Automotive Test Automation & Validation*

---

## ğŸ“œ License

Licensed under the **MIT License** â€” free to use, modify, and distribute with attribution.

---

### âœ… Summary

This project demonstrates how **AI + RAG + prompt engineering** can automate traditionally manual engineering processes â€” transforming **requirement analysis** into **automated, structured test case generation**.
