{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627095c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & setup\n",
    "# import re\n",
    "# import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import docx\n",
    "import openpyxl\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8eb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Utility functions for text extraction\n",
    "def extract_text_from_pdf(path: str) -> str:\n",
    "    reader = PdfReader(path)\n",
    "    pages = []\n",
    "    for p in reader.pages:\n",
    "        try:\n",
    "            pages.append(p.extract_text() or \"\")\n",
    "        except Exception:\n",
    "            pages.append(\"\")\n",
    "    return \"\\n\".join(pages)\n",
    "\n",
    "def extract_text_from_docx(path: str) -> str:\n",
    "    doc = docx.Document(path)\n",
    "    return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "def extract_text_from_txt(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_text_from_xlsx(path: str) -> str:\n",
    "    wb = openpyxl.load_workbook(path, data_only=True)\n",
    "    texts = []\n",
    "    for sheet in wb.worksheets:\n",
    "        for row in sheet.iter_rows(values_only=True):\n",
    "            row_txt = \" \".join(\"\" if v is None else str(v) for v in row)\n",
    "            texts.append(row_txt)\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "def extract_text(path: str) -> str:\n",
    "    p = Path(path)\n",
    "    if p.suffix.lower() == \".pdf\":\n",
    "        return extract_text_from_pdf(str(p))\n",
    "    if p.suffix.lower() in [\".docx\", \".doc\"]:\n",
    "        return extract_text_from_docx(str(p))\n",
    "    if p.suffix.lower() in [\".txt\", \".md\"]:\n",
    "        return extract_text_from_txt(str(p))\n",
    "    if p.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "        return extract_text_from_xlsx(str(p))\n",
    "    try:\n",
    "        return extract_text_from_txt(str(p))\n",
    "    except Exception:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "507f0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Chunking utility\n",
    "def chunk_text(text: str, chunk_size: int = 800, overlap: int = 200) -> List[str]:\n",
    "    cleaned = \" \".join(text.split())\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    L = len(cleaned)\n",
    "    while i < L:\n",
    "        end = min(i + chunk_size, L)\n",
    "        chunks.append(cleaned[i:end])\n",
    "        i = end - overlap if end < L else end\n",
    "    return [c for c in chunks if len(c.strip()) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbd315c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RAG index builder class\n",
    "class SimpleRAGIndex:\n",
    "    def __init__(self, embedding_model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[RAG] Loading embedding model on device: {device}\")\n",
    "        self.model = SentenceTransformer(embedding_model_name, device=device)\n",
    "        self.dim = self.model.get_sentence_embedding_dimension()\n",
    "        self.index = None\n",
    "        self.metadatas = []\n",
    "\n",
    "    def build(self, docs: List[Tuple[str, str]], batch_size: int = 64):\n",
    "        all_chunks = []\n",
    "        metas = []\n",
    "        for doc_id, text in docs:\n",
    "            chunks = chunk_text(text)\n",
    "            for i, c in enumerate(chunks):\n",
    "                metas.append({\"doc_id\": doc_id, \"chunk_id\": f\"{doc_id}__{i}\", \"text\": c})\n",
    "                all_chunks.append(c)\n",
    "        embs = []\n",
    "        for i in range(0, len(all_chunks), batch_size):\n",
    "            batch = all_chunks[i:i+batch_size]\n",
    "            print(f\"[Embedding] batch {i}/{len(all_chunks)}\")\n",
    "            emb = self.model.encode(batch, convert_to_numpy=True, show_progress_bar=False, device=self.model.device)\n",
    "            embs.append(emb)\n",
    "        vectors = np.vstack(embs).astype(\"float32\") if embs else np.zeros((0, self.dim), dtype='float32')\n",
    "        self.index = faiss.IndexFlatL2(self.dim)\n",
    "        self.index.add(vectors)\n",
    "        self.metadatas = metas\n",
    "        print(f\"[RAG] Built index with {self.index.ntotal} vectors.\")\n",
    "\n",
    "    def retriever(self, query: str, top_k: int = 6) -> List[Dict]:\n",
    "        q_emb = self.model.encode([query], convert_to_numpy=True, device=self.model.device).astype(\"float32\")\n",
    "        D, I = self.index.search(q_emb, top_k)\n",
    "        results = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            if idx < 0 or idx >= len(self.metadatas):\n",
    "                continue\n",
    "            meta = dict(self.metadatas[idx])\n",
    "            meta[\"score\"] = float(score)\n",
    "            results.append(meta)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb9418c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Mistral API call (strict JSON output)\n",
    "def call_mistral_generate(api_key: str, prompt: str, model: str,\n",
    "                          max_tokens: int, temperature: float = 0.0) -> str:\n",
    "    \"\"\"\n",
    "    Mistral Chat API call with strict system instruction to return ONLY valid JSON.\n",
    "    \"\"\"\n",
    "    url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that ONLY outputs strictly valid JSON. \"\n",
    "                                          \"No markdown, no comments, no explanations. \"\n",
    "                                          \"If unsure, output an empty JSON object {\\\"tests\\\": []}.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"❌ Error:\", resp.status_code, resp.text)\n",
    "        resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0c1f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Prompt template (strict JSON, with style rules)\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert automotive HMI test author. \n",
    "Your ONLY task is to output a **valid JSON object** with the following schema:\n",
    "\n",
    "{\n",
    "  \"tests\": [\n",
    "    {\n",
    "      \"test_name\": \"string\",\n",
    "      \"test_description\": \"string\",\n",
    "      \"steps\": [\n",
    "        {\n",
    "          \"step_name\": \"string\",\n",
    "          \"action\": \"string\",\n",
    "          \"expected_result\": \"string\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "===== STYLE RULES (MANDATORY) =====\n",
    "1. Test Name:\n",
    "   - Must start with a 3-digit sequence number (001_, 002_, 003_, …).\n",
    "   - Then repeat the test description text.\n",
    "   - Example: \"001_To Check the Availability of Plug and charge during different MMI states\".\n",
    "\n",
    "2. Test Description:\n",
    "   - Should be identical to the Test Name but without the 3-digit prefix.\n",
    "   - Example: \"To Check the Availability of Plug and charge during different MMI states\".\n",
    "\n",
    "3. Step Names:\n",
    "   - Always numbered: \"Step 1\", \"Step 2\", \"Step 3\", restarting at Step 1 for each test case.\n",
    "   - Never use descriptive names like \"Activate Plug & Charge\". Only \"Step X\".\n",
    "\n",
    "4. Action Descriptions:\n",
    "   - Must be **multi-line and descriptive**, not single short sentences.\n",
    "   - Should include: preconditions, configurations, CAN signals, and actions.\n",
    "   - Use bullet points or numbered sub-steps when needed (just as in the expected output).\n",
    "\n",
    "5. Expected Results:\n",
    "   - Must exist for EVERY step.\n",
    "   - Write them clearly, not vague. If unclear, set to: \"Observe / Verify behavior matches requirement\".\n",
    "\n",
    "===== Example (shortened) =====\n",
    "{\n",
    "  \"tests\": [\n",
    "    {\n",
    "      \"test_name\": \"001_To Check the Availability of Plug and charge during different MMI states\",\n",
    "      \"test_description\": \"To Check the Availability of Plug and charge during different MMI states\",\n",
    "      \"steps\": [\n",
    "        {\n",
    "          \"step_name\": \"Step 1\",\n",
    "          \"action\": \"Set Below Condition:\\\\n+ Bat Unit Powered\\\\n+ Power State - ON\\\\n+ Language: English\",\n",
    "          \"expected_result\": \"Is the user able to set the preconditions?\"\n",
    "        },\n",
    "        {\n",
    "          \"step_name\": \"Step 2\",\n",
    "          \"action\": \"Set below CAN signals:\\\\n1. V_WakeUpType = 000 (Full Wake-Up Mode) [Frame: BCM_A110]\\\\n2. V_WakeUpSleepCommand = 11 (WakeUp) [Frame: BCM_A110]\",\n",
    "          \"expected_result\": \"Plug and Charge feature should not be available during 'Check Welcome screen'.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "===== INPUTS =====\n",
    "Requirements excerpt (the new doc to test):\n",
    "<<<INCOMING_REQ>>>\n",
    "\n",
    "Relevant context from indexed documents (RAG):\n",
    "{context}\n",
    "\n",
    "===== FINAL INSTRUCTIONS =====\n",
    "- Ensure output is valid JSON (no comments, no markdown, no trailing commas).\n",
    "- Follow the style rules strictly.\n",
    "- Return ONLY JSON, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6adda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Parse the output safely\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_json_strict(s: str):\n",
    "    \"\"\"Strip markdown fences/BOM and parse strict JSON.\"\"\"\n",
    "    s = s.strip()\n",
    "    s = s.lstrip(\"\\ufeff\")          # remove BOM if present\n",
    "    s = re.sub(r\"^\\s*```json\", \"\", s)\n",
    "    s = re.sub(r\"```$\", \"\", s)\n",
    "    return json.loads(s)\n",
    "\n",
    "\n",
    "def safe_json_parse(raw: str, chunk_id, api_key, model) -> dict:\n",
    "    \"\"\"\n",
    "    Parse model output into JSON safely.\n",
    "    If parsing fails, call Mistral again to repair/complete the JSON.\n",
    "    \"\"\"\n",
    "    cleaned = raw.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    start, end = cleaned.find(\"{\"), cleaned.rfind(\"}\")\n",
    "    if start == -1 or end == -1:\n",
    "        raise ValueError(\"No JSON object found in model output.\")\n",
    "    json_str = cleaned[start:end+1]\n",
    "\n",
    "    # --- cleanup ---\n",
    "    json_str = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", json_str)  # remove trailing commas\n",
    "    json_str = re.sub(r\"[\\x00-\\x1F]\", \"\", json_str)     # remove control chars\n",
    "\n",
    "    try:\n",
    "        data = load_json_strict(json_str)\n",
    "    except Exception:\n",
    "        # Save broken output\n",
    "        fname = f\"failed_chunk_{chunk_id or 'unknown'}.json\"\n",
    "        with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw)\n",
    "        print(f\"⚠️ Saved broken JSON to {fname}. Attempting repair with Mistral...\")\n",
    "\n",
    "        if api_key and model:\n",
    "            repair_prompt = f\"\"\"\n",
    "You are given partial or invalid JSON for automotive test cases.\n",
    "Please fix it so that it becomes strictly valid JSON, following this schema:\n",
    "\n",
    "{{\n",
    "  \"tests\": [\n",
    "    {{\n",
    "      \"test_name\": \"string\",\n",
    "      \"test_description\": \"string\",\n",
    "      \"steps\": [\n",
    "        {{\n",
    "          \"step_name\": \"string\",\n",
    "          \"action\": \"string\",\n",
    "          \"expected_result\": \"string\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Broken JSON starts below:\n",
    "{json_str}\n",
    "\n",
    "Return ONLY the corrected JSON.\n",
    "\"\"\"\n",
    "            fixed = call_mistral_generate(\n",
    "                api_key=api_key,\n",
    "                prompt=repair_prompt,\n",
    "                model=model,\n",
    "                max_tokens=1600\n",
    "            )\n",
    "            try:\n",
    "                data = load_json_strict(fixed)\n",
    "            except Exception as e2:\n",
    "                fname2 = f\"failed_chunk_{chunk_id or 'unknown'}_repair.json\"\n",
    "                with open(fname2, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(fixed)\n",
    "                raise RuntimeError(f\"❌ Repair attempt also failed. Saved to {fname2}\\nError: {e2}\")\n",
    "        else:\n",
    "            raise RuntimeError(f\"❌ JSON parse failed for chunk {chunk_id}. No repair attempted (missing API key/model).\")\n",
    "\n",
    "    # --- numbering enforcement ---\n",
    "    tests = data.get(\"tests\", [])\n",
    "    for i, t in enumerate(tests, start=1):\n",
    "        desc = t.get(\"test_description\", \"\").strip()\n",
    "        if not desc:\n",
    "            continue\n",
    "        prefix = f\"{i:03d}_\"\n",
    "        if not t.get(\"test_name\", \"\").startswith(prefix):\n",
    "            t[\"test_name\"] = prefix + desc\n",
    "        t[\"test_description\"] = desc\n",
    "        for j, s in enumerate(t.get(\"steps\", []), start=1):\n",
    "            s[\"step_name\"] = f\"Step {j}\"\n",
    "\n",
    "    return {\"tests\": tests}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312bc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Load docs\n",
    "index_dir = \"./requirements_docs\"\n",
    "query_doc = \"./PlugNCharge_requirements_doc.xlsx\"\n",
    "mistral_api_key = \"YOUR_MISTRAL_API_KEY_HERE\"  # replace with your key\n",
    "out_excel = \"./generated_tests.xlsx\"\n",
    "embed_model = \"sentence-transformers/all-MiniLM-L6-v2\"  # faster\n",
    "mistral_model = \"codestral-2508\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b6aaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save to Excel\n",
    "def tests_to_excel(tests: List[Dict], out_path: str):\n",
    "    rows = []\n",
    "    for t in tests:\n",
    "        test_name, test_desc = t.get(\"test_name\", \"\"), t.get(\"test_description\", \"\")\n",
    "        steps = t.get(\"steps\", [])\n",
    "        if not steps:\n",
    "            rows.append({\n",
    "                \"Test Name\": test_name,\n",
    "                \"Test Description\": test_desc,\n",
    "                \"Step Name\": \"\",\n",
    "                \"Action Description\": \"\",\n",
    "                \"Expected Results\": \"\"\n",
    "            })\n",
    "        else:\n",
    "            for s in steps:\n",
    "                rows.append({\n",
    "                    \"Test Name\": test_name,\n",
    "                    \"Test Description\": test_desc,\n",
    "                    \"Step Name\": s.get(\"step_name\", \"\"),\n",
    "                    \"Action Description\": s.get(\"action\", \"\").replace(\"\\n\", \"\\n\"),\n",
    "                    \"Expected Results\": s.get(\"expected_result\", \"\")\n",
    "                })\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"Test Name\", \"Test Description\", \"Step Name\", \"Action Description\", \"Expected Results\"\n",
    "    ])\n",
    "    # Excel preserves line breaks if keep_default_na=False and strings contain \"\\n\"\n",
    "    df.to_excel(out_path, index=False, engine=\"openpyxl\")\n",
    "    print(f\"[Output] written {len(df)} rows to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "166a804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Indexing] found 7 documents to index.\n",
      "[RAG] Loading embedding model on device: cuda\n",
      "[Embedding] batch 0/31258\n",
      "[Embedding] batch 64/31258\n",
      "[Embedding] batch 128/31258\n",
      "[Embedding] batch 192/31258\n",
      "[Embedding] batch 256/31258\n",
      "[Embedding] batch 320/31258\n",
      "[Embedding] batch 384/31258\n",
      "[Embedding] batch 448/31258\n",
      "[Embedding] batch 512/31258\n",
      "[Embedding] batch 576/31258\n",
      "[Embedding] batch 640/31258\n",
      "[Embedding] batch 704/31258\n",
      "[Embedding] batch 768/31258\n",
      "[Embedding] batch 832/31258\n",
      "[Embedding] batch 896/31258\n",
      "[Embedding] batch 960/31258\n",
      "[Embedding] batch 1024/31258\n",
      "[Embedding] batch 1088/31258\n",
      "[Embedding] batch 1152/31258\n",
      "[Embedding] batch 1216/31258\n",
      "[Embedding] batch 1280/31258\n",
      "[Embedding] batch 1344/31258\n",
      "[Embedding] batch 1408/31258\n",
      "[Embedding] batch 1472/31258\n",
      "[Embedding] batch 1536/31258\n",
      "[Embedding] batch 1600/31258\n",
      "[Embedding] batch 1664/31258\n",
      "[Embedding] batch 1728/31258\n",
      "[Embedding] batch 1792/31258\n",
      "[Embedding] batch 1856/31258\n",
      "[Embedding] batch 1920/31258\n",
      "[Embedding] batch 1984/31258\n",
      "[Embedding] batch 2048/31258\n",
      "[Embedding] batch 2112/31258\n",
      "[Embedding] batch 2176/31258\n",
      "[Embedding] batch 2240/31258\n",
      "[Embedding] batch 2304/31258\n",
      "[Embedding] batch 2368/31258\n",
      "[Embedding] batch 2432/31258\n",
      "[Embedding] batch 2496/31258\n",
      "[Embedding] batch 2560/31258\n",
      "[Embedding] batch 2624/31258\n",
      "[Embedding] batch 2688/31258\n",
      "[Embedding] batch 2752/31258\n",
      "[Embedding] batch 2816/31258\n",
      "[Embedding] batch 2880/31258\n",
      "[Embedding] batch 2944/31258\n",
      "[Embedding] batch 3008/31258\n",
      "[Embedding] batch 3072/31258\n",
      "[Embedding] batch 3136/31258\n",
      "[Embedding] batch 3200/31258\n",
      "[Embedding] batch 3264/31258\n",
      "[Embedding] batch 3328/31258\n",
      "[Embedding] batch 3392/31258\n",
      "[Embedding] batch 3456/31258\n",
      "[Embedding] batch 3520/31258\n",
      "[Embedding] batch 3584/31258\n",
      "[Embedding] batch 3648/31258\n",
      "[Embedding] batch 3712/31258\n",
      "[Embedding] batch 3776/31258\n",
      "[Embedding] batch 3840/31258\n",
      "[Embedding] batch 3904/31258\n",
      "[Embedding] batch 3968/31258\n",
      "[Embedding] batch 4032/31258\n",
      "[Embedding] batch 4096/31258\n",
      "[Embedding] batch 4160/31258\n",
      "[Embedding] batch 4224/31258\n",
      "[Embedding] batch 4288/31258\n",
      "[Embedding] batch 4352/31258\n",
      "[Embedding] batch 4416/31258\n",
      "[Embedding] batch 4480/31258\n",
      "[Embedding] batch 4544/31258\n",
      "[Embedding] batch 4608/31258\n",
      "[Embedding] batch 4672/31258\n",
      "[Embedding] batch 4736/31258\n",
      "[Embedding] batch 4800/31258\n",
      "[Embedding] batch 4864/31258\n",
      "[Embedding] batch 4928/31258\n",
      "[Embedding] batch 4992/31258\n",
      "[Embedding] batch 5056/31258\n",
      "[Embedding] batch 5120/31258\n",
      "[Embedding] batch 5184/31258\n",
      "[Embedding] batch 5248/31258\n",
      "[Embedding] batch 5312/31258\n",
      "[Embedding] batch 5376/31258\n",
      "[Embedding] batch 5440/31258\n",
      "[Embedding] batch 5504/31258\n",
      "[Embedding] batch 5568/31258\n",
      "[Embedding] batch 5632/31258\n",
      "[Embedding] batch 5696/31258\n",
      "[Embedding] batch 5760/31258\n",
      "[Embedding] batch 5824/31258\n",
      "[Embedding] batch 5888/31258\n",
      "[Embedding] batch 5952/31258\n",
      "[Embedding] batch 6016/31258\n",
      "[Embedding] batch 6080/31258\n",
      "[Embedding] batch 6144/31258\n",
      "[Embedding] batch 6208/31258\n",
      "[Embedding] batch 6272/31258\n",
      "[Embedding] batch 6336/31258\n",
      "[Embedding] batch 6400/31258\n",
      "[Embedding] batch 6464/31258\n",
      "[Embedding] batch 6528/31258\n",
      "[Embedding] batch 6592/31258\n",
      "[Embedding] batch 6656/31258\n",
      "[Embedding] batch 6720/31258\n",
      "[Embedding] batch 6784/31258\n",
      "[Embedding] batch 6848/31258\n",
      "[Embedding] batch 6912/31258\n",
      "[Embedding] batch 6976/31258\n",
      "[Embedding] batch 7040/31258\n",
      "[Embedding] batch 7104/31258\n",
      "[Embedding] batch 7168/31258\n",
      "[Embedding] batch 7232/31258\n",
      "[Embedding] batch 7296/31258\n",
      "[Embedding] batch 7360/31258\n",
      "[Embedding] batch 7424/31258\n",
      "[Embedding] batch 7488/31258\n",
      "[Embedding] batch 7552/31258\n",
      "[Embedding] batch 7616/31258\n",
      "[Embedding] batch 7680/31258\n",
      "[Embedding] batch 7744/31258\n",
      "[Embedding] batch 7808/31258\n",
      "[Embedding] batch 7872/31258\n",
      "[Embedding] batch 7936/31258\n",
      "[Embedding] batch 8000/31258\n",
      "[Embedding] batch 8064/31258\n",
      "[Embedding] batch 8128/31258\n",
      "[Embedding] batch 8192/31258\n",
      "[Embedding] batch 8256/31258\n",
      "[Embedding] batch 8320/31258\n",
      "[Embedding] batch 8384/31258\n",
      "[Embedding] batch 8448/31258\n",
      "[Embedding] batch 8512/31258\n",
      "[Embedding] batch 8576/31258\n",
      "[Embedding] batch 8640/31258\n",
      "[Embedding] batch 8704/31258\n",
      "[Embedding] batch 8768/31258\n",
      "[Embedding] batch 8832/31258\n",
      "[Embedding] batch 8896/31258\n",
      "[Embedding] batch 8960/31258\n",
      "[Embedding] batch 9024/31258\n",
      "[Embedding] batch 9088/31258\n",
      "[Embedding] batch 9152/31258\n",
      "[Embedding] batch 9216/31258\n",
      "[Embedding] batch 9280/31258\n",
      "[Embedding] batch 9344/31258\n",
      "[Embedding] batch 9408/31258\n",
      "[Embedding] batch 9472/31258\n",
      "[Embedding] batch 9536/31258\n",
      "[Embedding] batch 9600/31258\n",
      "[Embedding] batch 9664/31258\n",
      "[Embedding] batch 9728/31258\n",
      "[Embedding] batch 9792/31258\n",
      "[Embedding] batch 9856/31258\n",
      "[Embedding] batch 9920/31258\n",
      "[Embedding] batch 9984/31258\n",
      "[Embedding] batch 10048/31258\n",
      "[Embedding] batch 10112/31258\n",
      "[Embedding] batch 10176/31258\n",
      "[Embedding] batch 10240/31258\n",
      "[Embedding] batch 10304/31258\n",
      "[Embedding] batch 10368/31258\n",
      "[Embedding] batch 10432/31258\n",
      "[Embedding] batch 10496/31258\n",
      "[Embedding] batch 10560/31258\n",
      "[Embedding] batch 10624/31258\n",
      "[Embedding] batch 10688/31258\n",
      "[Embedding] batch 10752/31258\n",
      "[Embedding] batch 10816/31258\n",
      "[Embedding] batch 10880/31258\n",
      "[Embedding] batch 10944/31258\n",
      "[Embedding] batch 11008/31258\n",
      "[Embedding] batch 11072/31258\n",
      "[Embedding] batch 11136/31258\n",
      "[Embedding] batch 11200/31258\n",
      "[Embedding] batch 11264/31258\n",
      "[Embedding] batch 11328/31258\n",
      "[Embedding] batch 11392/31258\n",
      "[Embedding] batch 11456/31258\n",
      "[Embedding] batch 11520/31258\n",
      "[Embedding] batch 11584/31258\n",
      "[Embedding] batch 11648/31258\n",
      "[Embedding] batch 11712/31258\n",
      "[Embedding] batch 11776/31258\n",
      "[Embedding] batch 11840/31258\n",
      "[Embedding] batch 11904/31258\n",
      "[Embedding] batch 11968/31258\n",
      "[Embedding] batch 12032/31258\n",
      "[Embedding] batch 12096/31258\n",
      "[Embedding] batch 12160/31258\n",
      "[Embedding] batch 12224/31258\n",
      "[Embedding] batch 12288/31258\n",
      "[Embedding] batch 12352/31258\n",
      "[Embedding] batch 12416/31258\n",
      "[Embedding] batch 12480/31258\n",
      "[Embedding] batch 12544/31258\n",
      "[Embedding] batch 12608/31258\n",
      "[Embedding] batch 12672/31258\n",
      "[Embedding] batch 12736/31258\n",
      "[Embedding] batch 12800/31258\n",
      "[Embedding] batch 12864/31258\n",
      "[Embedding] batch 12928/31258\n",
      "[Embedding] batch 12992/31258\n",
      "[Embedding] batch 13056/31258\n",
      "[Embedding] batch 13120/31258\n",
      "[Embedding] batch 13184/31258\n",
      "[Embedding] batch 13248/31258\n",
      "[Embedding] batch 13312/31258\n",
      "[Embedding] batch 13376/31258\n",
      "[Embedding] batch 13440/31258\n",
      "[Embedding] batch 13504/31258\n",
      "[Embedding] batch 13568/31258\n",
      "[Embedding] batch 13632/31258\n",
      "[Embedding] batch 13696/31258\n",
      "[Embedding] batch 13760/31258\n",
      "[Embedding] batch 13824/31258\n",
      "[Embedding] batch 13888/31258\n",
      "[Embedding] batch 13952/31258\n",
      "[Embedding] batch 14016/31258\n",
      "[Embedding] batch 14080/31258\n",
      "[Embedding] batch 14144/31258\n",
      "[Embedding] batch 14208/31258\n",
      "[Embedding] batch 14272/31258\n",
      "[Embedding] batch 14336/31258\n",
      "[Embedding] batch 14400/31258\n",
      "[Embedding] batch 14464/31258\n",
      "[Embedding] batch 14528/31258\n",
      "[Embedding] batch 14592/31258\n",
      "[Embedding] batch 14656/31258\n",
      "[Embedding] batch 14720/31258\n",
      "[Embedding] batch 14784/31258\n",
      "[Embedding] batch 14848/31258\n",
      "[Embedding] batch 14912/31258\n",
      "[Embedding] batch 14976/31258\n",
      "[Embedding] batch 15040/31258\n",
      "[Embedding] batch 15104/31258\n",
      "[Embedding] batch 15168/31258\n",
      "[Embedding] batch 15232/31258\n",
      "[Embedding] batch 15296/31258\n",
      "[Embedding] batch 15360/31258\n",
      "[Embedding] batch 15424/31258\n",
      "[Embedding] batch 15488/31258\n",
      "[Embedding] batch 15552/31258\n",
      "[Embedding] batch 15616/31258\n",
      "[Embedding] batch 15680/31258\n",
      "[Embedding] batch 15744/31258\n",
      "[Embedding] batch 15808/31258\n",
      "[Embedding] batch 15872/31258\n",
      "[Embedding] batch 15936/31258\n",
      "[Embedding] batch 16000/31258\n",
      "[Embedding] batch 16064/31258\n",
      "[Embedding] batch 16128/31258\n",
      "[Embedding] batch 16192/31258\n",
      "[Embedding] batch 16256/31258\n",
      "[Embedding] batch 16320/31258\n",
      "[Embedding] batch 16384/31258\n",
      "[Embedding] batch 16448/31258\n",
      "[Embedding] batch 16512/31258\n",
      "[Embedding] batch 16576/31258\n",
      "[Embedding] batch 16640/31258\n",
      "[Embedding] batch 16704/31258\n",
      "[Embedding] batch 16768/31258\n",
      "[Embedding] batch 16832/31258\n",
      "[Embedding] batch 16896/31258\n",
      "[Embedding] batch 16960/31258\n",
      "[Embedding] batch 17024/31258\n",
      "[Embedding] batch 17088/31258\n",
      "[Embedding] batch 17152/31258\n",
      "[Embedding] batch 17216/31258\n",
      "[Embedding] batch 17280/31258\n",
      "[Embedding] batch 17344/31258\n",
      "[Embedding] batch 17408/31258\n",
      "[Embedding] batch 17472/31258\n",
      "[Embedding] batch 17536/31258\n",
      "[Embedding] batch 17600/31258\n",
      "[Embedding] batch 17664/31258\n",
      "[Embedding] batch 17728/31258\n",
      "[Embedding] batch 17792/31258\n",
      "[Embedding] batch 17856/31258\n",
      "[Embedding] batch 17920/31258\n",
      "[Embedding] batch 17984/31258\n",
      "[Embedding] batch 18048/31258\n",
      "[Embedding] batch 18112/31258\n",
      "[Embedding] batch 18176/31258\n",
      "[Embedding] batch 18240/31258\n",
      "[Embedding] batch 18304/31258\n",
      "[Embedding] batch 18368/31258\n",
      "[Embedding] batch 18432/31258\n",
      "[Embedding] batch 18496/31258\n",
      "[Embedding] batch 18560/31258\n",
      "[Embedding] batch 18624/31258\n",
      "[Embedding] batch 18688/31258\n",
      "[Embedding] batch 18752/31258\n",
      "[Embedding] batch 18816/31258\n",
      "[Embedding] batch 18880/31258\n",
      "[Embedding] batch 18944/31258\n",
      "[Embedding] batch 19008/31258\n",
      "[Embedding] batch 19072/31258\n",
      "[Embedding] batch 19136/31258\n",
      "[Embedding] batch 19200/31258\n",
      "[Embedding] batch 19264/31258\n",
      "[Embedding] batch 19328/31258\n",
      "[Embedding] batch 19392/31258\n",
      "[Embedding] batch 19456/31258\n",
      "[Embedding] batch 19520/31258\n",
      "[Embedding] batch 19584/31258\n",
      "[Embedding] batch 19648/31258\n",
      "[Embedding] batch 19712/31258\n",
      "[Embedding] batch 19776/31258\n",
      "[Embedding] batch 19840/31258\n",
      "[Embedding] batch 19904/31258\n",
      "[Embedding] batch 19968/31258\n",
      "[Embedding] batch 20032/31258\n",
      "[Embedding] batch 20096/31258\n",
      "[Embedding] batch 20160/31258\n",
      "[Embedding] batch 20224/31258\n",
      "[Embedding] batch 20288/31258\n",
      "[Embedding] batch 20352/31258\n",
      "[Embedding] batch 20416/31258\n",
      "[Embedding] batch 20480/31258\n",
      "[Embedding] batch 20544/31258\n",
      "[Embedding] batch 20608/31258\n",
      "[Embedding] batch 20672/31258\n",
      "[Embedding] batch 20736/31258\n",
      "[Embedding] batch 20800/31258\n",
      "[Embedding] batch 20864/31258\n",
      "[Embedding] batch 20928/31258\n",
      "[Embedding] batch 20992/31258\n",
      "[Embedding] batch 21056/31258\n",
      "[Embedding] batch 21120/31258\n",
      "[Embedding] batch 21184/31258\n",
      "[Embedding] batch 21248/31258\n",
      "[Embedding] batch 21312/31258\n",
      "[Embedding] batch 21376/31258\n",
      "[Embedding] batch 21440/31258\n",
      "[Embedding] batch 21504/31258\n",
      "[Embedding] batch 21568/31258\n",
      "[Embedding] batch 21632/31258\n",
      "[Embedding] batch 21696/31258\n",
      "[Embedding] batch 21760/31258\n",
      "[Embedding] batch 21824/31258\n",
      "[Embedding] batch 21888/31258\n",
      "[Embedding] batch 21952/31258\n",
      "[Embedding] batch 22016/31258\n",
      "[Embedding] batch 22080/31258\n",
      "[Embedding] batch 22144/31258\n",
      "[Embedding] batch 22208/31258\n",
      "[Embedding] batch 22272/31258\n",
      "[Embedding] batch 22336/31258\n",
      "[Embedding] batch 22400/31258\n",
      "[Embedding] batch 22464/31258\n",
      "[Embedding] batch 22528/31258\n",
      "[Embedding] batch 22592/31258\n",
      "[Embedding] batch 22656/31258\n",
      "[Embedding] batch 22720/31258\n",
      "[Embedding] batch 22784/31258\n",
      "[Embedding] batch 22848/31258\n",
      "[Embedding] batch 22912/31258\n",
      "[Embedding] batch 22976/31258\n",
      "[Embedding] batch 23040/31258\n",
      "[Embedding] batch 23104/31258\n",
      "[Embedding] batch 23168/31258\n",
      "[Embedding] batch 23232/31258\n",
      "[Embedding] batch 23296/31258\n",
      "[Embedding] batch 23360/31258\n",
      "[Embedding] batch 23424/31258\n",
      "[Embedding] batch 23488/31258\n",
      "[Embedding] batch 23552/31258\n",
      "[Embedding] batch 23616/31258\n",
      "[Embedding] batch 23680/31258\n",
      "[Embedding] batch 23744/31258\n",
      "[Embedding] batch 23808/31258\n",
      "[Embedding] batch 23872/31258\n",
      "[Embedding] batch 23936/31258\n",
      "[Embedding] batch 24000/31258\n",
      "[Embedding] batch 24064/31258\n",
      "[Embedding] batch 24128/31258\n",
      "[Embedding] batch 24192/31258\n",
      "[Embedding] batch 24256/31258\n",
      "[Embedding] batch 24320/31258\n",
      "[Embedding] batch 24384/31258\n",
      "[Embedding] batch 24448/31258\n",
      "[Embedding] batch 24512/31258\n",
      "[Embedding] batch 24576/31258\n",
      "[Embedding] batch 24640/31258\n",
      "[Embedding] batch 24704/31258\n",
      "[Embedding] batch 24768/31258\n",
      "[Embedding] batch 24832/31258\n",
      "[Embedding] batch 24896/31258\n",
      "[Embedding] batch 24960/31258\n",
      "[Embedding] batch 25024/31258\n",
      "[Embedding] batch 25088/31258\n",
      "[Embedding] batch 25152/31258\n",
      "[Embedding] batch 25216/31258\n",
      "[Embedding] batch 25280/31258\n",
      "[Embedding] batch 25344/31258\n",
      "[Embedding] batch 25408/31258\n",
      "[Embedding] batch 25472/31258\n",
      "[Embedding] batch 25536/31258\n",
      "[Embedding] batch 25600/31258\n",
      "[Embedding] batch 25664/31258\n",
      "[Embedding] batch 25728/31258\n",
      "[Embedding] batch 25792/31258\n",
      "[Embedding] batch 25856/31258\n",
      "[Embedding] batch 25920/31258\n",
      "[Embedding] batch 25984/31258\n",
      "[Embedding] batch 26048/31258\n",
      "[Embedding] batch 26112/31258\n",
      "[Embedding] batch 26176/31258\n",
      "[Embedding] batch 26240/31258\n",
      "[Embedding] batch 26304/31258\n",
      "[Embedding] batch 26368/31258\n",
      "[Embedding] batch 26432/31258\n",
      "[Embedding] batch 26496/31258\n",
      "[Embedding] batch 26560/31258\n",
      "[Embedding] batch 26624/31258\n",
      "[Embedding] batch 26688/31258\n",
      "[Embedding] batch 26752/31258\n",
      "[Embedding] batch 26816/31258\n",
      "[Embedding] batch 26880/31258\n",
      "[Embedding] batch 26944/31258\n",
      "[Embedding] batch 27008/31258\n",
      "[Embedding] batch 27072/31258\n",
      "[Embedding] batch 27136/31258\n",
      "[Embedding] batch 27200/31258\n",
      "[Embedding] batch 27264/31258\n",
      "[Embedding] batch 27328/31258\n",
      "[Embedding] batch 27392/31258\n",
      "[Embedding] batch 27456/31258\n",
      "[Embedding] batch 27520/31258\n",
      "[Embedding] batch 27584/31258\n",
      "[Embedding] batch 27648/31258\n",
      "[Embedding] batch 27712/31258\n",
      "[Embedding] batch 27776/31258\n",
      "[Embedding] batch 27840/31258\n",
      "[Embedding] batch 27904/31258\n",
      "[Embedding] batch 27968/31258\n",
      "[Embedding] batch 28032/31258\n",
      "[Embedding] batch 28096/31258\n",
      "[Embedding] batch 28160/31258\n",
      "[Embedding] batch 28224/31258\n",
      "[Embedding] batch 28288/31258\n",
      "[Embedding] batch 28352/31258\n",
      "[Embedding] batch 28416/31258\n",
      "[Embedding] batch 28480/31258\n",
      "[Embedding] batch 28544/31258\n",
      "[Embedding] batch 28608/31258\n",
      "[Embedding] batch 28672/31258\n",
      "[Embedding] batch 28736/31258\n",
      "[Embedding] batch 28800/31258\n",
      "[Embedding] batch 28864/31258\n",
      "[Embedding] batch 28928/31258\n",
      "[Embedding] batch 28992/31258\n",
      "[Embedding] batch 29056/31258\n",
      "[Embedding] batch 29120/31258\n",
      "[Embedding] batch 29184/31258\n",
      "[Embedding] batch 29248/31258\n",
      "[Embedding] batch 29312/31258\n",
      "[Embedding] batch 29376/31258\n",
      "[Embedding] batch 29440/31258\n",
      "[Embedding] batch 29504/31258\n",
      "[Embedding] batch 29568/31258\n",
      "[Embedding] batch 29632/31258\n",
      "[Embedding] batch 29696/31258\n",
      "[Embedding] batch 29760/31258\n",
      "[Embedding] batch 29824/31258\n",
      "[Embedding] batch 29888/31258\n",
      "[Embedding] batch 29952/31258\n",
      "[Embedding] batch 30016/31258\n",
      "[Embedding] batch 30080/31258\n",
      "[Embedding] batch 30144/31258\n",
      "[Embedding] batch 30208/31258\n",
      "[Embedding] batch 30272/31258\n",
      "[Embedding] batch 30336/31258\n",
      "[Embedding] batch 30400/31258\n",
      "[Embedding] batch 30464/31258\n",
      "[Embedding] batch 30528/31258\n",
      "[Embedding] batch 30592/31258\n",
      "[Embedding] batch 30656/31258\n",
      "[Embedding] batch 30720/31258\n",
      "[Embedding] batch 30784/31258\n",
      "[Embedding] batch 30848/31258\n",
      "[Embedding] batch 30912/31258\n",
      "[Embedding] batch 30976/31258\n",
      "[Embedding] batch 31040/31258\n",
      "[Embedding] batch 31104/31258\n",
      "[Embedding] batch 31168/31258\n",
      "[Embedding] batch 31232/31258\n",
      "[RAG] Built index with 31258 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Build RAG\n",
    "docs = []\n",
    "for p in Path(index_dir).glob(\"*\"):\n",
    "    if p.is_file():\n",
    "        txt = extract_text(str(p))\n",
    "        docs.append((p.name, txt))\n",
    "print(f\"[Indexing] found {len(docs)} documents to index.\")\n",
    "\n",
    "# Build RAG (only once!)\n",
    "rag = SimpleRAGIndex(embedding_model_name=embed_model)\n",
    "rag.build(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22c038b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Extract input text\n",
    "incoming_text = extract_text(query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1a8d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Chunked test generation workflow\n",
    "def generate_tests_chunked(\n",
    "    rag: SimpleRAGIndex,\n",
    "    incoming_text: str,\n",
    "    api_key: str = mistral_api_key,\n",
    "    model: str = mistral_model,\n",
    "    chunk_size: int = 2000,\n",
    "    overlap: int = 500\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Split incoming_text into smaller chunks, generate test cases per chunk,\n",
    "    and merge results.\n",
    "    \"\"\"\n",
    "    chunks = chunk_text(incoming_text, chunk_size=chunk_size, overlap=overlap)\n",
    "    print(f\"[Chunked] split incoming doc into {len(chunks)} chunks.\")\n",
    "\n",
    "    all_tests = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\n[Chunk {i+1}/{len(chunks)}] processing...\")\n",
    "        retrieved = rag.retriever(chunk, top_k=3)\n",
    "        context_blocks = \"\\n\\n---\\n\\n\".join([f\"[{r['doc_id']}|score={r['score']}]\\n{r['text']}\" for r in retrieved])\n",
    "        prompt = PROMPT_TEMPLATE.replace(\"{context}\", context_blocks).replace(\"<<<INCOMING_REQ>>>\", chunk[:1500])\n",
    "\n",
    "        raw = call_mistral_generate(api_key=api_key, prompt=prompt, model=model, max_tokens=1200, temperature=0.0)\n",
    "\n",
    "        try:\n",
    "            payload = safe_json_parse(raw, chunk_id=i+1, api_key=mistral_api_key, model=mistral_model)\n",
    "            tests = payload.get(\"tests\", [])\n",
    "            print(f\"   -> got {len(tests)} tests.\")\n",
    "            all_tests.extend(tests)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed to parse chunk {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Final renumbering across all chunks\n",
    "    for i, t in enumerate(all_tests, start=1):\n",
    "        desc = t.get(\"test_description\", \"\").strip()\n",
    "        prefix = f\"{i:03d}_\"\n",
    "        t[\"test_name\"] = prefix + desc if desc else f\"{prefix}Untitled Test\"\n",
    "        t[\"test_description\"] = desc if desc else t[\"test_name\"]\n",
    "        for j, s in enumerate(t.get(\"steps\", []), start=1):\n",
    "            s[\"step_name\"] = f\"Step {j}\"\n",
    "\n",
    "    print(f\"[Chunked] total tests collected: {len(all_tests)}\")\n",
    "    return all_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3473282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunked] split incoming doc into 8 chunks.\n",
      "\n",
      "[Chunk 1/8] processing...\n",
      "   -> got 2 tests.\n",
      "\n",
      "[Chunk 2/8] processing...\n",
      "   -> got 2 tests.\n",
      "\n",
      "[Chunk 3/8] processing...\n",
      "   -> got 2 tests.\n",
      "\n",
      "[Chunk 4/8] processing...\n",
      "   -> got 3 tests.\n",
      "\n",
      "[Chunk 5/8] processing...\n",
      "   -> got 2 tests.\n",
      "\n",
      "[Chunk 6/8] processing...\n",
      "⚠️ Saved broken JSON to failed_chunk_6.json. Attempting repair with Mistral...\n",
      "   -> got 4 tests.\n",
      "\n",
      "[Chunk 7/8] processing...\n",
      "   -> got 0 tests.\n",
      "\n",
      "[Chunk 8/8] processing...\n",
      "   -> got 2 tests.\n",
      "[Chunked] total tests collected: 17\n",
      "[Output] written 59 rows to ./generated_tests.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Save to Excel\n",
    "tests = generate_tests_chunked(\n",
    "    rag,\n",
    "    incoming_text,\n",
    "    api_key=mistral_api_key,\n",
    "    model=mistral_model\n",
    ")\n",
    "\n",
    "tests_to_excel(tests, out_excel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
